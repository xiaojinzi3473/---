{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern RNN (Recurrent Neural Networks)\n",
    "\n",
    "### 循环神经网络进阶\n",
    "\n",
    "**- GRU(Gated Recurrent Unit) 门控循环网络 LSTM变体 **\n",
    "\n",
    "**- LSTM(Long-Short-Term-Memories) 长短期记忆网络 **\n",
    "\n",
    "**- 深层RNN **\n",
    "\n",
    "**- 双向RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "#### GRU与LSTM总结\n",
    "https://blog.csdn.net/lreaderl/article/details/78022724"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 习题\n",
    "\n",
    "选择题\n",
    "\n",
    "### 1.LSTM单元中控制当前时间步输入的结构是？\n",
    "\n",
    "A.遗忘门\n",
    "\n",
    "B.输入门\n",
    "\n",
    "C.输出门\n",
    "\n",
    "D.记忆细胞\n",
    "\n",
    "#### 答案：B\n",
    "\n",
    "答案解释\n",
    "\n",
    "参考视频中输入门的定义\n",
    "\n",
    "### 2.实现深层循环神经网络需要修改的参数是？\n",
    "\n",
    "A.input_size\n",
    "\n",
    "B.hidden_size\n",
    "\n",
    "C.bidirectional\n",
    "\n",
    "D.num_layers\n",
    "\n",
    "#### 答案：D\n",
    "\n",
    "答案解释\n",
    "\n",
    "参考视频24分50秒左右\n",
    "\n",
    "### 3.下列关于GRU说法正确的是？\n",
    "\n",
    "A.GRU有遗忘门、更新门两种门控结构\n",
    "\n",
    "B.GRU中重置门有助于捕捉时间序列里长期的依赖关系\n",
    "\n",
    "C.GRU中更新门有助于捕捉时间序列里长期的依赖关系\n",
    "\n",
    "D.GRU中遗忘门有助于捕捉时间序列里长期的依赖关系\n",
    "\n",
    "#### 答案：C\n",
    "\n",
    "答案解释\n",
    "\n",
    "GRU有重置门和更新门，没有遗忘门。重置门有助于捕捉时间序列里短期的依赖关系，更新门有助于捕捉时间序列⾥长期的依赖关系。参考视频1分20秒起关于GRU的原理讲解。\n",
    "\n",
    "### 4.在LSTM模型的初始化中，下列不需要初始化的参数是？\n",
    "\n",
    "A.每个循环单元中的记忆细胞和循环单元的值\n",
    "\n",
    "B.第0个循环单元的记忆细胞和循环单元的值\n",
    "\n",
    "C.门控单元中用于计算遗忘门的权重与偏差\n",
    "\n",
    "D.用于计算输出的权重与偏差\n",
    "\n",
    "#### 答案：A\n",
    "\n",
    "答案解释\n",
    "\n",
    "每个循环单元中的记忆细胞和循环单元的值为LSTM模型中的隐状态，而非参数，因此不需要初始化。\n",
    "\n",
    "### 5.下列关于RNN的说法错误的是？\n",
    "\n",
    "A.GRU、LSTM都能捕捉时间序列中时间步距离较⼤的依赖关系。\n",
    "\n",
    "B.双向循环神经网络在文本任务里能做到同时考虑上文和下文与当前词之间的依赖。\n",
    "\n",
    "C.LSTM和GRU能一定程度缓解梯度消失与梯度爆炸的问题。\n",
    "\n",
    "D.深层循环网络能有效抽取更高层更抽象的信息，层数越深效果越好。\n",
    "\n",
    "#### 答案：D\n",
    "\n",
    "答案解释\n",
    "\n",
    "层数越深效果未必越好，层数的加深会导致模型的收敛变得困难。\n",
    "\n",
    "### 6.双向循环神经网络前向和后向RNN连结的方式是\n",
    "\n",
    "A.前向的output和后向的output用concat进行连结\n",
    "\n",
    "B.前向的$H_t$和后向的$H_t$用concat进行连结\n",
    "\n",
    "C.前向的output和后向的output按元素相加\n",
    "\n",
    "D.前向的$H_t$和后向的$H_t$按元素相加\n",
    "\n",
    "#### 答案：B\n",
    "\n",
    "答案解释\n",
    "\n",
    "参考视频27分45秒左右。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(10)\n",
    "w = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000, 2.5000,\n",
       "        2.5000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5505, -0.6513],\n",
       "        [-0.1308,  0.8378],\n",
       "        [-1.5610, -0.5843],\n",
       "        [-0.9865,  0.5920],\n",
       "        [-0.7375, -0.4201],\n",
       "        [ 2.2606,  0.9286],\n",
       "        [ 0.7264, -1.3176],\n",
       "        [-0.4865, -0.9557],\n",
       "        [ 0.0201,  0.9662],\n",
       "        [-0.8094,  3.3333]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = torch.tensor([2])\n",
    "w2 = torch.tensor([[2],[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  6],\n",
       "        [ 8, 12]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4],\n",
       "        [8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.tensor([[2, 1],\n",
    "                   [4, 3],\n",
    "                   [1,3]])\n",
    "w3 =[2, 3]\n",
    "y3 = w3[0] * x3[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 8, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y4 = w3[1] * x3[:,1]\n",
    "y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1],\n",
       "        [4, 3],\n",
       "        [1, 3]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 17, 11])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = y3 + y4\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = torch.arange(10).view(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1027\n",
    "n_class = 1027\n",
    "def one_hot(x, n_class, dtype=torch.float32):\n",
    "    result = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)  # shape: (n, n_class)\n",
    "    result.scatter_(1, x.long().view(-1, 1), 1)  # result[i, x[i, 0]] = 1\n",
    "    return result\n",
    "\n",
    "def to_onehot(X, n_class):\n",
    "    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]\n",
    "\n",
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = to_onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot(X[:, 0],1027)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 5])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1027])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
